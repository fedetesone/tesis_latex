\subsection{Resumen de resultados}

En el análisis del método EQuAL, mediante experimentación con distintos parámetros (tamaño de muestra y número de clusters), se obtuvo una media de error mínima de \(0.312\) para el tamaño de muestra de \(100\) pares de preguntas y \(k = 50\). Esta tendencia en los resultados demuestra dos particularidades: el método EQuAL tuvo buen rendimiento con tamaño de muestras chicas y con un alto número de clusters. Esta tendencia en tamaños de muestra chicos puede ser consecuencia del agregado de variabilidad que este método proporciona. Por otro lado, la tendencia a la baja de media de error es mucho más clara con valores de \(k\) altos, obteniendo un valor muy bueno cuando \(k = 50\). Luego de ese valor, la mejora no es significativa.

\bigskip Por otro lado, comparando el método EQuAL con los algoritmos del estado del arte, se concluye que posee indicadores aptos para su aplicación en RSs, en cuanto a medias de error y varianza. La media de error total del método EQuAL (teniendo en cuenta todas las ejecuciones realizadas en los experimentos) es de \(0.32286\), la cual no difiere demasiado de la mejor (bow con \(0.31162\)) y supera a FastText y TFIDF con \(0.33124\) y \(0.32409\) respectivamente.

\bigskip Se realizó un Análisis de Varianza del método propuesto en contraste con los métodos del estado del arte para poder afirmar que el método EQuAL es apto para ser aplicado en RS, de forma eficiente y eficaz, de forma estadísticamente significativa. En la mayoría de los tamaños de muestra analizados, la media de error fue estadísticamente igual en comparación con cada uno de los métodos del estado del arte, con excepción de una oportunidad. En muchas oportunidades el método EQuAL fue superador.

\bigskip Adicionalmente, es posible afirmar que el método propuesto depende tanto de los algoritmos subyacentes como del conjunto de datos de entrada. Por un lado, es altamente probable que arroje buenos resultados si los algoritmos subyacentes también lo hacen, y viceversa. Por otro lado, es posible adaptarlo al conjunto de datos y elegir los algoritmos subyacentes adecuados para el mismo, dando versatilidad y un resultado compuesto por características aportadas por cada uno de ellos.

\bigskip Para finalizar, se desarrolló una arquitectura de software que realiza los cálculos de similaridad y procesamiento del ensamble de clustering de forma distribuida, la cual es escalable horizontalmente permitiendo incrementar el rendimiento de manera exponencial, solo con un cambio de configuración de la infraestructura base.
