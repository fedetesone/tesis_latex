\subsection{Método de validación}\label{metodo-validacion}

\subsubsection{Generación de conjuntos estadísticamente significativos}

Para generar resultados estadísticamente significativos se ejecutó el proceso completo de modo iterativo, variando dos parámetros principales: \begin{enumerate*} [label=(\roman*)] \item el tamaño de la muestra y \item el número de clusters \(k\)\end{enumerate*}. Como experimentos para este trabajo se realizaron ejecuciones con conjuntos de datos aleatorios de 100, 500, 1000, 1500 y 2000 pares de preguntas (200, 1000, 2000, 3000 y 4000 preguntas individuales). Para cada tamaño de muestra, se realizaron 10 muestras aleatorias manteniendo un \(k\) fijo. Por ejemplo, para un número de clusters \(k = 5\) y para un tamaño de muestra 100, se realizaron 10 ejecuciones con un conjunto de datos de entrada aleatorio. Dando un total de \(5 \times 10 = 50\) matrices de co-asociación resultado, para un valor de \(k\) dado.

\paragraph{Elección de los tamaños de muestra}
En cuanto a la elección del tamaño de muestra en el apartado anterior, se tomó en cuenta que los conjuntos de datos sean lo suficientemente grandes como para generar resultados estadísticamente significativos, pero con un tamaño apropiado para la ejecución de los experimentos de forma local, en favor de la facilidad que para la depuración de los mismos. Cuando se aumenta el tamaño de la muestra en forma lineal, la cantidad de cómputos por cada uno de los algoritmos de similaridad aumentan de forma cuadrática. Como se mencionó anteriormente, Siendo \(n\) el número de pares de preguntas de una muestra, se realizarán \(2n^2-n\) cálculos. Además, si, por ejemplo, utilizamos 5 algoritmos de similaridad el número de cálculos de similaridad es de \(5(2n^2-n)\), con el agregado de que al algoritmos de clustering PAM y el ensamble de clustering también aumentan su complejidad de una forma considerable, dependiendo de nuestro número de clusters \(k\).

\paragraph{Elección del número de clusters}
La elección del número de clusters \(k\) en los experimentos realizados sigue una lógica que busca estandarizar a los mismos a lo largo de todos los tamaños de muestras, es decir, no variar el número de clusters entre ellas, con fines de comparación. Como regla general (\textit{rule of thumb} o \textit{regla del pulgar}) se considera como número ``óptimo'' de clusters un valor de alrededor de \(\sqrt{n/2}\) \citep{kodinariya2013review}, siendo \(n\) el tamaño de la muestra. Para el número de muestras elegido (200, 1000, 2000, 3000 y 4000 preguntas individuales), los valores siguiendo esta regla serían \(k = 10\), \(k = 22\), \(k = 31\), \(k = 38\), \(k =44\).

\bigskip Los valores generados por la regla del pulgar se encuentran en un rango \([10, 44]\), por lo cual, finalmente se optó por elegir los valores de \(k\) con una separación uniforme de los mismos, para facilitar su interpretación y visualización, respetando ese rango de cobertura. Los experimentos para este trabajo se realizaron con los valores \(k = 5, 10, 15, 20, 25, 30, 35, 40, 45, 50\).

\bigskip La validación de los valores de \(k\) elegidos para realizar los experimentos fueron validados en conjunto mediante el rendimiento de la matriz de co-asociación. Partiendo de la base del \textit{método del codo} para la evaluación del rendimiento de un algoritmo de clustering, el cual evalúa el porcentaje de variabilidad (suma de cuadrados de distancias) explicada en función del número de clusters, mediante la idea de encontrar el número mínimo de clusters por el cual agregando un cluster adicional no modelaría mejor los datos. El porcentaje de variabilidad explicado por los clusters es graficado contra el número de clusters. Los primeros clusters agregaran una información considerable al modelo, pero en cierto punto la ganancia marginal caerá dramáticamente, dando un ángulo en el gráfico \citep{bholowalia2014ebk}. La Figura \ref{fig:codo} muestra un gráfico bidimensional en el cual se compara el número de clusters (en abscisas) y la suma de cuadrados de distancias (en ordenadas) como medida de variabilidad de los clusters. En este gráfico se puede ver como luego de \(k = 5\), la suma de cuadrados de distancias varía muy poco, ya que los valores esbozan una curva con valores aproximadamente constantes a partir de este punto.

\begin{filecontents*}{codo.csv}
1,400
2,200
3,130
4,80
5,40
6,25
7,24
8,23
9,22
10,21
11,20
12,19
\end{filecontents*}

\begin{figure}
	\centering
	\scriptsize
	\resizebox{\textwidth}{!}{%
		\begin{tikzpicture}
			\begin{axis}[
				xlabel={Número de clusters (k)},
				ylabel={Suma de cuadrados de distancias},
				xmin=0, xmax=12,
				ymin=0, ymax=420,
				xtick={1,2,...,12},
				ytick={0,50,...,400},
				legend pos=north west,
				ymajorgrids=true,
				grid style=dashed,
				]

				\addplot table [mark=square,x index=0, y index=1, col sep=comma] {codo.csv};
				\label{codo}

				\draw [dashed] (50,0) -- (50,400);
			\end{axis}
		\end{tikzpicture}
	}
	\caption{Ejemplo de gráfico para método del codo. Valor óptimo \(k = 5\).}
	\label{fig:codo}
\end{figure}

\bigskip Con el fin de dar una aplicación más integral al método del codo, en lugar de calcularlo por cada una de las técnicas de clustering aplicadas, el mismo se aplicó utilizando la matriz de co-asociación generada a partir del ensamble. Para cuantificar y evaluar el rendimiento, se utilizó matrices de confusión que indican el error entre los resultados obtenidos y la clasificación proveniente del conjunto de datos original, por cada uno de los valores de \(k\) anteriormente mencionados.

\subsubsection{Estructura de las matrices de confusión}\label{estructurasconfusion}
Una matriz de confusión, es una matriz que muestra clasificaciones predichas y reales. Una matriz de confusión puede ser de tamaño \(L \times L\) donde \(L\) es el número de diferentes valores de etiqueta o clase \citep{provost1998glossary}. En este trabajo, las clases son: 0 (las preguntas comparadas no son iguales) y 1 (las preguntas son iguales). Por lo cual, la matriz de confusión que se deriva, se muestra en la Tabla \ref{tab:matriz-confusion}. Los valores “a” y “d” representan el porcentaje de veces que los valores predichos fueron iguales a los reales, es decir, los casos en que las preguntas fueron predichas, respectivamente, iguales o distintas y realmente lo eran. Por otro lado, “c” es la proporción de preguntas predichas distintas, que en realidad son iguales; y “b” la proporción de preguntas predichas iguales, pero son realmente distintas. El objetivo de un algoritmo con buen desempeño entonces, es maximizar “a” y “d” y, por lo tanto, minimizar “b” y “c”.

\bigskip
\begin{table}[h!]
	\footnotesize
	\centering
	\caption{Matriz de confusión para validación de resultados.}
	\begin{tabularx}{0.35\textwidth}{*{7}{>{\centering\arraybackslash}X}}
		\toprule
		\multicolumn{2}{l}{\multirow{2}{*}{}} & \multicolumn{2}{c}{\textbf{Predicho}}                             \\ \cmidrule(l){3-4}
		\multicolumn{2}{l}{}                  & \multicolumn{1}{c}{\textbf{0}} & \multicolumn{1}{c}{\textbf{1}} \\ \midrule
		\multicolumn{1}{c}{\multirow{2}{*}{\textbf{Real}}} & \multicolumn{1}{c}{\textbf{0}} & \multicolumn{1}{c}{a} & \multicolumn{1}{c}{b} \\ \cmidrule(l){2-4}
		\multicolumn{1}{c}{}  & \textbf{1}  & c                               & d                               \\ \bottomrule
	\end{tabularx}
	\label{tab:matriz-confusion}
\end{table}

Los indicadores de desempeño que se evaluaron en los experimentos realizados con fines comparativos, son los siguientes:
\begin{itemize}
	\item \textbf{Exactitud:} \((a+d)/(a+b+c+d)\)
	\item \textbf{Error:} \((b+c)/(a+b+c+d)\)
\end{itemize}
donde \(a+b+c+d=1\).

\paragraph{Preparación de los datos}
Para evaluar el rendimiento del algoritmo de ensamble, se toma la matriz de co-asociación generada como resultado del proceso total y la muestra de pares de preguntas que se utilizó como entrada para ese proceso. Por ejemplo, se considera la muestra de preguntas de la Tabla \ref{tab:muestra-validacion}, la cual muestra dos pares de preguntas (\(123004\) y \(98776\) - 4 preguntas en total) con su identificador de par y un indicador en la columna \(equal\), que tiene dos valores posibles: 1 (preguntas iguales) y 0 (preguntas distintas). Por otro lado, en la Tabla \ref{tab:coasociacion-validacion}, se muestra la matriz de co-asociación generada, por el método EQuAL, a partir de la Tabla \ref{tab:muestra-validacion}, teniendo en cuenta todas las combinaciones tomadas de a 2 de las 4 preguntas originales, para las cuales se agrega la similaridad entre pares, en la columna similarity. Por último, se filtran solo los pares de preguntas de la matriz de co-asociación que se encuentran en la Tabla \ref{tab:muestra-validacion}, ya que son las únicas con la cual su similaridad puede compararse con fines de validación, es decir, el conjunto de datos mostrado en la Tabla \ref{tab:filtrado-validacion}. Lo que nos deja con un conjunto de pares de preguntas que es posible comparar en su totalidad con la muestra original.

\begin{table}[h!]
	\footnotesize
	\centering
	\caption{Muestras de pares de preguntas que se utilizó como entrada del método EQuAL.}
	\begin{tabularx}{0.8\textwidth}{*{7}{>{\centering\arraybackslash}c}}
		\toprule
		\textbf{sequence\_id} & \textbf{question\_pair\_id} & \textbf{question\_1} & \textbf{question\_2} & \textbf{equal} \\
		\midrule
		0                     & 123004                      & question\_10         & question\_20         & 1              \\
		1                     & 98776                       & question\_11         & question\_21         & 0              \\
		\bottomrule
	\end{tabularx}
	\label{tab:muestra-validacion}
\end{table}

\begin{table}[h!]
	\footnotesize
	\caption{Matriz de co-asociación generada a partir de la muestra de la Tabla \ref{tab:muestra-validacion}.}
	\begin{tabularx}{\textwidth}{*{7}{>{\centering\arraybackslash}X}}
		\toprule
		\textbf{question\_id\_1} & \textbf{question\_id\_2} & \textbf{question\_1} & \textbf{question\_2} & \textbf{similarity} \\
		\midrule
		question\_10 & question\_11 & contenido & contenido & 0.857 \\
		question\_10 & question\_20 & contenido & contenido & 0.210 \\
		question\_10 & question\_21 & contenido & contenido & 0.126 \\
		question\_11 & question\_20 & contenido & contenido & 0.006 \\
		question\_11 & question\_21 & contenido & contenido & 0.368 \\
		question\_20 & question\_21 & contenido & contenido & 0.146 \\
		\bottomrule
	\end{tabularx}
	\label{tab:coasociacion-validacion}
\end{table}

\begin{table}[h!]
	\footnotesize
	\caption{Filtrado de la Tabla \ref{tab:coasociacion-validacion} con los pares de preguntas que se encuentran en la Tabla \ref{tab:muestra-validacion}.}
	\begin{tabularx}{\textwidth}{*{7}{>{\centering\arraybackslash}X}}
		\toprule
		\textbf{question\_id\_1} & \textbf{question\_id\_2} & \textbf{question\_1} & \textbf{question\_2} & \textbf{similarity} \\
		\midrule
		question\_10             & question\_11             & contenido            & contenido            & 0.857               \\
		question\_11             & question\_21             & contenido            & contenido            & 0.368               \\
		\bottomrule
	\end{tabularx}
	\label{tab:filtrado-validacion}
\end{table}

Ya se realizaron los cálculos de similaridad, los algoritmos de clustering y la matriz de co-asociación. En la siguiente sección, se procederá a interpretar los resultados obtenidos.

\paragraph{Construcción y elección del umbral correcto}
La problemática que se intenta resolver teniendo en cuenta todas las similaridades obtenidas a partir del ensamble de clustering es ¿Cuándo consideramos a esas preguntas iguales y cuándo no? La respuesta es simple, cuando la similaridad \(S\) entre un par de preguntas (\(q_1,q_2)\) es igual o superior a cierto umbral \(t\) se considera que son iguales (1) y distintas si sucede lo contrario (0), clarificando:
\[f(x) = \left\{ \begin{array}{lcc} 1 & si & S(q_1, q_2)\geq t
	\\ 0 & si & S(q_1, q_2) < t
\end{array} \right.\]

La elección del mejor umbral, se realiza eligiendo valores en el intervalo \((0,1)\) y evaluando cual de ellos conlleva a un mejor rendimiento, es decir, que los valores calculados a partir del umbral coincidan, en una mayor medida, con el valor real proveniente de la muestra de datos. Por ejemplo, tomando valores potenciales de umbral con intervalos \(0.05\) se forma un arreglo como \([0.05, 0.1, 0.15, ..., 0.90, 0.95]\) y se itera cada uno de ellos. Por cada uno de los valores en el arreglo:
\begin{enumerate}
	\item Se iteran todos los pares de preguntas tomadas en cuenta, provenientes de la matriz de co-asociación.
	\item Por cada uno de los valores de similaridad, se asigna \(1\) si son mayores o iguales al umbral, \(0\) si pasa lo contrario.
	\item Si los valores asignados en el paso anterior coinciden con el valor real, se asigna un valor \textit{true} (verdadero), si no coinciden, se asigna \textit{false} (falso).
	\item Se calcula la proporción de pares de preguntas asignadas con \textit{true}, es decir, que el valor real coincide con el predicho, y se obtiene la \textit{exactitud} del método.
\end{enumerate}
El valor de umbral que arroje la mayor exactitud, será el utilizado para evaluar el desempeño del método al construir la matriz de confusión.

\bigskip Volviendo al ejemplo anterior, un umbral elegido de \(0.65\) aplicado a la Tabla \ref{tab:filtrado-validacion}, arrojaría el resultado de la Tabla \ref{tab:umbral-validacion-1} (el único par de preguntas que presenta una similaridad mayor al umbral es \((question\_10, question\_11)\), por lo cual se le asigna el valor 1). La Tabla \ref{tab:umbral-validacion-1}, muestra un resultado idéntico al conjunto de entrada, es decir, a la Tabla \ref{tab:muestra-validacion}. Lo anterior significa que los pares predichos son iguales a los pares reales. En otro caso, si el umbral que tiene mejor rendimiento fuese \(0.9\), el resultado obtenido luego del cómputo hubiese sido el de la Tabla \ref{tab:umbral-validacion-2}, el cual expone una diferencia entre el valor real y el predicho del par de preguntas \((question\_10, question\_11)\). Lo anterior denota el mayor rendimiento del umbral \(0.65\) contra el umbral \(0.9\) y su importancia en la elección del valor correcto.

\bigskip

\begin{table}[h!]
	\footnotesize
	\caption{Asignación binaria de los resultados de similaridad obtenidos en la Tabla \ref{tab:filtrado-validacion}, teniendo en cuenta un umbral de \(0.65\).}
	\begin{tabularx}{\textwidth}{*{7}{>{\centering\arraybackslash}X}}
		\toprule
		\textbf{question\_id\_1} & \textbf{question\_id\_2} & \textbf{question\_1} & \textbf{question\_2} & \textbf{equal} \\
		\midrule
		question\_10             & question\_11             & contenido            & contenido            & 1              \\
		question\_11             & question\_21             & contenido            & contenido            & 0              \\
		\bottomrule
	\end{tabularx}
	\label{tab:umbral-validacion-1}
\end{table}


\begin{table}[h!]
	\footnotesize
	\caption{Asignación binaria de los resultados de similaridad obtenidos en la Tabla \ref{tab:filtrado-validacion}, teniendo en cuenta un umbral de \(0.9\).}
	\begin{tabularx}{\textwidth}{*{7}{>{\centering\arraybackslash}X}}
		\toprule
		\textbf{question\_id\_1} & \textbf{question\_id\_2} & \textbf{question\_1} & \textbf{question\_2} & \textbf{equal} \\
		\midrule
		question\_10             & question\_11             & contenido            & contenido            & 0              \\
		question\_11             & question\_21             & contenido            & contenido            & 0              \\
		\bottomrule
	\end{tabularx}
	\label{tab:umbral-validacion-2}
\end{table}

\bigskip En conclusión, el rendimiento del algoritmo se medirá comparando la variable de clase (1 o 0) del conjunto de datos de entrada, con la variable de clase construida desde la comparación de las similaridades resultados del método y un umbral apropiado. Cuantos más pares de preguntas coincidan, mejor será el rendimiento del algoritmo, el cual se podrá visualizar mediante matrices de confusión.

\paragraph{Construcción de las matrices de confusión}
Con el fin de poder ilustrar cómo se construyen las matrices de confusión a partir de la comparación de los conjuntos de datos, se utilizará el siguiente ejemplo. Supongamos que el conjunto de datos de entrada es el que se muestra en la Tabla \ref{tab:validacion-reales}, Y el resultado obtenido luego de la elección del mejor umbral, es la Tabla \ref{tab:validacion-predichos}. Por lo cual, comparando los valores de la columna “equal", obtendremos el resultado de la Tabla \ref{tab:validacion-comparacion}. Sumarizando los resultados, la matriz de confusión derivada se muestra en la Tabla \ref{tab:validacion-confusion-ejemplo}. La exactitud obtenida a partir de este conjunto de datos y la ejecución hipotética del método es \(0.75\) (y por lo tanto, el error es \(0.25\)).

\begin{table}[h!]
	\footnotesize
	\centering
	\caption{Ejemplo de conjunto de datos de entrada (reales) para validación.}
	\begin{tabularx}{0.8\textwidth}{*{7}{>{\centering\arraybackslash}c}}
		\toprule
		\textbf{sequence\_id} & \textbf{question\_pair\_id} & \textbf{question\_1} & \textbf{question\_2} & \textbf{equal} \\
		\midrule
		0 & 123004 & question\_10 & question\_20 & 1 \\
		1 & 98776  & question\_11 & question\_21 & 1 \\
		2 & 14422  & question\_12 & question\_22 & 1 \\
		3 & 12321  & question\_13 & question\_23 & 1 \\
		4 & 999    & question\_14 & question\_24 & 0 \\
		5 & 7448   & question\_15 & question\_25 & 0 \\
		6 & 69553  & question\_16 & question\_26 & 0 \\
		7 & 2447   & question\_17 & question\_27 & 1 \\
		\bottomrule
	\end{tabularx}
	\label{tab:validacion-reales}
\end{table}

\begin{table}[h!]
	\footnotesize
	\centering
	\caption{Ejemplo de conjunto de datos de predichos por el método EQuAL.}
	\begin{tabularx}{0.8\textwidth}{*{7}{>{\centering\arraybackslash}c}}
		\toprule
		\textbf{question\_id\_1} & \textbf{question\_id\_2} & \textbf{question\_1} & \textbf{question\_2} & \textbf{equal} \\
		\midrule
		question\_id\_10 & question\_id\_20 &question\_10 & question\_20 & 1 \\
		question\_id\_11 & question\_id\_21 & question\_11 & question\_21 & 1 \\
		question\_id\_12 & question\_id\_22 & question\_12 & question\_22 & 0 \\
		question\_id\_13 & question\_id\_23 & question\_13 & question\_23 & 1 \\
		question\_id\_14 & question\_id\_24 & question\_14 & question\_24 & 1 \\
		question\_id\_15 & question\_id\_25 & question\_15 & question\_25 & 0 \\
		question\_id\_16 & question\_id\_26 & question\_16 & question\_26 & 0 \\
		question\_id\_17 & question\_id\_27 & question\_17 & question\_27 & 1 \\
		\bottomrule
	\end{tabularx}
	\label{tab:validacion-predichos}
\end{table}

\begin{table}[h!]
	\footnotesize
	\centering
	\caption{Resultado de comparación de las tablas \ref{tab:validacion-reales} y \ref{tab:validacion-predichos} para validación y construcción de matrices de confusión.}
	\begin{tabularx}{0.6\textwidth}{*{7}{>{\centering\arraybackslash}c}}
		\toprule
		\textbf{sequence\_id} & \textbf{real} & \textbf{predicho} & \textbf{resultado} \\
		\midrule
		0 & 1 & 1 & true \\
		1 & 1 & 1 & true \\
		2 & 1 & 0 & false \\
		3 & 1 & 1 & true \\
		4 & 0 & 1 & false \\
		5 & 0 & 0 & true \\
		6 & 0 & 0 & true \\
		7 & 1 & 1 & true \\
		\bottomrule
	\end{tabularx}
	\label{tab:validacion-comparacion}
\end{table}

\begin{table}[h!]
	\footnotesize
	\centering
	\caption{Matriz de confusión obtenida a partir de la comparación de las tablas \ref{tab:validacion-reales} y \ref{tab:validacion-predichos}.}
	\begin{tabularx}{0.35\textwidth}{*{7}{>{\centering\arraybackslash}X}}
		\toprule
		\multicolumn{2}{l}{\multirow{2}{*}{}} & \multicolumn{2}{c}{\textbf{Predicho}}                             \\ \cmidrule(l){3-4}
		\multicolumn{2}{l}{}                  & \multicolumn{1}{c}{\textbf{0}} & \multicolumn{1}{c}{\textbf{1}} \\ \midrule
		\multicolumn{1}{c}{\multirow{2}{*}{\textbf{Real}}} & \multicolumn{1}{c}{\textbf{0}} & \multicolumn{1}{c}{0.25} & \multicolumn{1}{c}{0.125} \\ \cmidrule(l){2-4}
		\multicolumn{1}{c}{}  & \textbf{1}  & 0.125                               & 0.5                               \\ \bottomrule
	\end{tabularx}
	\label{tab:validacion-confusion-ejemplo}
\end{table}
